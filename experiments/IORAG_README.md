# IORAGï¼šåŸºäº LightRAG çš„ Darshan æ—¥å¿—çŸ¥è¯†å›¾è°±ç³»ç»Ÿ

> **IO + RAG = IORAG**: å°† Darshan I/O æ—¥å¿—è½¬æ¢ä¸ºå›¾è°±+å‘é‡æ··åˆçš„æ•°æ®åº“ï¼Œç”¨äºæ™ºèƒ½æŸ¥è¯¢å’Œå¼‚å¸¸æ£€æµ‹

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [å®Œæ•´ Workflow](#å®Œæ•´-workflow)
- [æ ¸å¿ƒè„šæœ¬è¯¦è§£](#æ ¸å¿ƒè„šæœ¬è¯¦è§£)
- [Signal è®¡ç®—è§„æ ¼](#signal-è®¡ç®—è§„æ ¼)
- [è®¾è®¡æ€è·¯](#è®¾è®¡æ€è·¯)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## é¡¹ç›®æ¦‚è¿°

### ğŸ¯ ç›®æ ‡

ä½¿ç”¨ LightRAG æ¡†æ¶ï¼Œå°† Darshan I/O æ—¥å¿—è½¬æ¢ä¸º **å›¾è°±ï¼ˆGraphï¼‰+ å‘é‡ï¼ˆVectorï¼‰** ç»“åˆçš„çŸ¥è¯†åº“ï¼Œå®ç°ï¼š

1. **æ™ºèƒ½æ£€ç´¢**ï¼šé€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢ I/O è¡Œä¸ºï¼ˆ"å“ªäº›æ–‡ä»¶çš„å¸¦å®½è¶…è¿‡ 1GB/sï¼Ÿ"ï¼‰
2. **å¼‚å¸¸æ£€æµ‹**ï¼šè¯†åˆ« I/O æ€§èƒ½å¼‚å¸¸æ¨¡å¼ï¼ˆéšæœºè®¿é—®ã€å…ƒæ•°æ®å¯†é›†ã€è´Ÿè½½ä¸å‡ç­‰ï¼‰
3. **å…³ç³»æ¨ç†**ï¼šç†è§£ Application â†’ Job â†’ Module â†’ Record â†’ File â†’ FileSystem çš„å±‚æ¬¡å…³ç³»
4. **å¯è§£é‡Šæ€§**ï¼šä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼Œä¾¿äºäººç±»ç†è§£

### ğŸ—ï¸ æ¶æ„

```
Raw Darshan Log (.darshan)
         â†“
   [darshan-parser]
         â†“
  Parsed Log (.txt)
         â†“
[process_darshan_signals_v2.4.py]  â† è®¡ç®— signals
         â†“
  Signal File (*_signals_v2.4.txt)
         â†“
[darshan_kg_builder_v2.1.py]  â† æ„å»º KG
         â†“
  KG JSON (*_kg.json)
         â†“
[generate_descriptions_v3.py]  â† æ·»åŠ æè¿°
         â†“
  KG with Descriptions (*_kg_with_desc.json)
         â†“
[parse_darshan_chunks.py]  â† æ·»åŠ  chunks
         â†“
  KG with Chunks (*_kg_with_chunks.json)
         â†“
[embed_kg_local.py]  â† ç”Ÿæˆ embeddings
         â†“
  Embeddings (entity & relation vectors)
         â†“
[load_custom_kg_to_lightrag.py]  â† åŠ è½½åˆ° LightRAG
         â†“
   LightRAG Instance
         â†“
  [Query with Natural Language] ğŸ¯
```

---

## å®Œæ•´ Workflow

### é˜¶æ®µ 0: å‡†å¤‡åŸå§‹æ—¥å¿—

```bash
# è§£å‹ Darshan æ—¥å¿—
chmod +x scripts/unpack-darshan-logs.sh
./scripts/unpack-darshan-logs.sh /path/to/darshan-logs-tarball/
```

**è¾“å…¥**: `logs.tar.gz`ï¼ˆåŒ…å«å¤šä¸ª `.darshan` æ–‡ä»¶ï¼‰
**è¾“å‡º**: è§£å‹åçš„ `.darshan` æ–‡ä»¶

### é˜¶æ®µ 1: è§£ææ—¥å¿—ä¸ºæ–‡æœ¬

```bash
# ä½¿ç”¨ darshan-parser è§£æäºŒè¿›åˆ¶æ—¥å¿—
darshan-parser input.darshan > output.txt
```

**è¾“å…¥**: `.darshan` äºŒè¿›åˆ¶æ–‡ä»¶
**è¾“å‡º**: æ–‡æœ¬æ ¼å¼çš„ counter æ•°æ®

### é˜¶æ®µ 2: è®¡ç®— Signals

```bash
python3 scripts/process_darshan_signals_v2.4.py \
    input.txt \
    -o output_signals_v2.4.txt
```

**è¾“å…¥**:
- Darshan è§£æåçš„æ–‡æœ¬æ—¥å¿—
- åŒ…å«æ‰€æœ‰åŸå§‹ countersï¼ˆPOSIX_OPENS, POSIX_READS, etc.ï¼‰

**è¾“å‡º**:
- Header: å®Œæ•´ä¿ç•™åŸå§‹æ—¥å¿— headerï¼ˆjob metadata, mount pointsï¼‰
- Job çº§åˆ«: 4 ä¸ªèšåˆæŒ‡æ ‡ï¼ˆtotal_bytes_read/written, total_reads/writesï¼‰
- Module çº§åˆ«: æ¯ä¸ªæ¨¡å—ï¼ˆPOSIX, STDIO, HEATMAPï¼‰çš„ 6 ä¸ªæ€§èƒ½æŒ‡æ ‡
- Record çº§åˆ«: æ¯ä¸ªæ–‡ä»¶è®¿é—®è®°å½•çš„ **100+ æ´¾ç”Ÿä¿¡å·**

**å®ç°**:
1. ä½¿ç”¨ `(module, rank, record_id)` ä¸‰å…ƒç»„ä½œä¸ºå”¯ä¸€é”®ï¼Œé¿å…å¤š rank è®°å½•è¦†ç›–
2. ä¸‰å±‚å±‚æ¬¡åŒ–è®¡ç®—ï¼šJob â†’ Module â†’ Record
3. NA å€¼å¤„ç†ï¼šæ•°å€¼å­—æ®µç”¨ `NA(reason)` æ ‡æ³¨ç¼ºå¤±åŸå› 
4. Signal å‘½åç©ºé—´éš”ç¦»ï¼šæ¯ä¸ª module section åªè§£æè¯¥ section çš„ records

**å…³é”® Signals**ï¼ˆè§ [Signal è®¡ç®—è§„æ ¼](#signal-è®¡ç®—è§„æ ¼)ï¼‰:
- æ—¶é—´æŒ‡æ ‡ï¼š`read_start_ts`, `read_end_ts`, `read_span`, `read_time`, `read_busy_frac`
- æ€§èƒ½æŒ‡æ ‡ï¼š`read_bw`, `write_bw`, `read_iops`, `write_iops`
- è®¿é—®æ¨¡å¼ï¼š`seq_ratio`, `consec_ratio`, `rw_switches`
- HEATMAP ä¸“ç”¨ï¼š`active_bins`, `peak_activity_bin`, `entropy_norm`, `top1_share`

### é˜¶æ®µ 3: æ„å»ºçŸ¥è¯†å›¾è°±

```bash
python experiments/darshan_kg_builder_v2.1.py \
    -i output_signals_v2.4.txt \
    -o output_kg.json
```

**è¾“å…¥**:
- Signal æ–‡ä»¶ï¼ˆv2.4+ æ ¼å¼ï¼‰
- åŒ…å« Job/Module/Record ä¸‰å±‚æ•°æ®

**è¾“å‡º**:
- LightRAG æ ¼å¼çš„ JSON æ–‡ä»¶
- åŒ…å« `entities` å’Œ `relationships` ä¸¤ä¸ªæ•°ç»„
- æ¯ä¸ªå®ä½“åŒ…å«æ‰€æœ‰ signal å€¼ä½œä¸ºå±æ€§

**å®ç°**:
1. **6 ç§å®ä½“ç±»å‹**:
   - `APPLICATION`: å¯æ‰§è¡Œæ–‡ä»¶æ ‡è¯†ï¼ˆ`App_{exe}`ï¼‰
   - `JOB`: å•æ¬¡ä½œä¸šå®ä¾‹ï¼ˆ`Job_{job_id}`ï¼‰
   - `MODULE`: I/O æ¨¡å—ï¼ˆ`{job_id}::{module_name}`ï¼‰
   - `RECORD`: æ–‡ä»¶è®¿é—®è®°å½•ï¼ˆ`{job_id}::{module}::{record_id}::rank{rank}`ï¼‰
   - `FILE`: æ–‡ä»¶å®ä½“ï¼ˆ`File_{file_path_norm}`ï¼‰
   - `FILESYSTEM`: æ–‡ä»¶ç³»ç»Ÿï¼ˆ`FS_{fs_type}_{mount_pt}`ï¼‰

2. **è¾¹ç±»å‹**:
   - `APPLICATION â†’ JOB (HAS_JOB)`: åº”ç”¨äº§ç”Ÿçš„ä½œä¸š
   - `JOB â†’ MODULE (HAS_MODULE)`: ä½œä¸šä½¿ç”¨çš„ I/O æ¨¡å—
   - `MODULE â†’ RECORD (HAS_RECORD)`: æ¨¡å—ä¸‹çš„è®¿é—®è®°å½•
   - `RECORD â†’ FILE (ON_FILE)`: è®°å½•è®¿é—®çš„æ–‡ä»¶
   - `FILE â†’ FILESYSTEM (ON_FILESYSTEM)`: æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶ç³»ç»Ÿ
   - `JOB â†’ FILESYSTEM (TOUCH_FILESYSTEM)`: ä½œä¸šè®¿é—®çš„æ–‡ä»¶ç³»ç»Ÿ

3. **å…³é”®è®¾è®¡**:
   - Record = Incident = æœ€å°å¯æ£€ç´¢å•å…ƒ
   - Signal å€¼å­˜å‚¨ä¸ºå®ä½“å±æ€§ï¼ˆè€Œéç‹¬ç«‹èŠ‚ç‚¹ï¼‰
   - NA å€¼ç”¨ `null` è¡¨ç¤ºï¼ŒåŸå› å­˜å‚¨åœ¨ `{field}_na_reason` å­—æ®µ
   - Mount table å­˜å‚¨ä¸º Job å±æ€§ï¼ˆè€Œéè¾¹ï¼‰

### é˜¶æ®µ 4: ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°

```bash
python3 scripts/generate_descriptions_v3.py \
    output_kg.json \
    output_kg_with_desc.json
```

**è¾“å…¥**:
- KG JSONï¼ˆå®ä½“å’Œå…³ç³»ï¼‰
- æ¯ä¸ªå®ä½“åŒ…å«åŸå§‹ signal å±æ€§

**è¾“å‡º**:
- æ›´æ–°åçš„ KG JSON
- æ¯ä¸ªå®ä½“çš„ `description` å­—æ®µå¡«å……è‡ªç„¶è¯­è¨€æ–‡æœ¬
- æ¯ä¸ªå…³ç³»çš„ `description` å­—æ®µå¡«å……è¿æ¥è¯­ä¹‰

**å®ç°**:
1. ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡æ¿ï¼ˆé’ˆå¯¹æ¯ç§å®ä½“ç±»å‹ï¼‰
2. å¡«å……æ¨¡æ¿å ä½ç¬¦ï¼ˆå¦‚ `{job_id}`, `{read_bw}`ï¼‰
3. å¤„ç† NA å€¼ï¼šæ˜¾ç¤ºåŸå› è€Œé"N/A"
4. ç»Ÿè®¡æ¨¡æ¿ä½¿ç”¨æƒ…å†µï¼š
   - å“ªäº›å ä½ç¬¦æ€»æ˜¯æœ‰å€¼
   - å“ªäº›å ä½ç¬¦ä»ä¸æœ‰å€¼
   - å“ªäº› JSON å±æ€§æœªè¢«ä½¿ç”¨

**æ¨¡æ¿ç¤ºä¾‹**ï¼ˆRECORDï¼‰:
```
This FILE I/O RECORD describes how {file_name} was accessed...
I/O activity begins at {io_start_ts} and spans {io_span} seconds...
Performance shows read bandwidth {read_bw} MB/s...
Access pattern: sequential ratio {seq_ratio}, consecutive ratio {consec_ratio}...
```

### é˜¶æ®µ 5: æ·»åŠ  Counter Chunks

```bash
python3 scripts/parse_darshan_chunks.py \
    --log raw_log.txt \
    --kg output_kg_with_desc.json \
    --output output_kg_with_chunks.json
```

**è¾“å…¥**:
- Raw Darshan logï¼ˆè§£æåçš„æ–‡æœ¬ï¼‰
- KG with descriptions

**è¾“å‡º**:
- æ›´æ–°åçš„ KG JSON
- æ–°å¢ `chunks` æ•°ç»„
- æ¯ä¸ª chunk åŒ…å«å¯¹åº”å®ä½“çš„åŸå§‹ counter æ–‡æœ¬

**å®ç°**:
1. è§£æ raw log ä¸­çš„æ‰€æœ‰ counter è¡Œ
2. æŒ‰å®ä½“åç§°åˆ†ç»„ï¼ˆMODULE, RECORD, FILE, FILESYSTEMï¼‰
3. ä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆ `chunk_text`ï¼ˆåŸå§‹ counter æ•°æ®ï¼‰
4. ç¤ºä¾‹ chunk:
   ```
   POSIX  -1  11610284057069735693  POSIX_OPENS  24  /home/file  /home  lustre
   POSIX  -1  11610284057069735693  POSIX_READS  100  /home/file  /home  lustre
   ...
   ```

### é˜¶æ®µ 6: ç”Ÿæˆ Embeddings

```bash
# ä½¿ç”¨ Gemma æ¨¡å‹ï¼ˆæ¨èï¼‰
python3 scripts/embed_kg_local.py \
    --kg output_kg_with_chunks.json \
    --output ./embeddings_gemma \
    --model google/embeddinggemma-300m \
    --batch-size 4 \
    --max-length 2048

# æˆ–ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼ˆCPU å‹å¥½ï¼‰
./scripts/embed_kg_cpu_optimized.sh
```

**è¾“å…¥**:
- KG with chunks
- æ¯ä¸ªå®ä½“æœ‰ `description` å’Œ `chunk_text`

**è¾“å‡º**:
- `entity_embeddings.pkl`: å®ä½“å‘é‡ï¼ˆentity_name + descriptionï¼‰
- `relationship_embeddings.pkl`: å…³ç³»å‘é‡ï¼ˆsrc_idâ†’tgt_id + descriptionï¼‰
- `embedding_metadata.json`: å…ƒæ•°æ®ï¼ˆæ¨¡å‹åç§°ã€ç»´åº¦ã€æ•°é‡ï¼‰

**å®ç°**:
1. åŠ è½½æœ¬åœ° Transformer æ¨¡å‹ï¼ˆæ— éœ€ APIï¼‰
2. å®ä½“æ–‡æœ¬ = `entity_name` + `description`
3. å…³ç³»æ–‡æœ¬ = `src_id â†’ tgt_id` + `description`
4. Batch å¤„ç†ï¼Œæ”¯æŒ CPU/GPU
5. Mean pooling + L2 normalization
6. ä¿å­˜ä¸º pickle å’Œ numpy æ ¼å¼

**æ¨èæ¨¡å‹**:
- `google/embeddinggemma-300m`: 768 ç»´ï¼Œé«˜ç²¾åº¦ï¼ˆé»˜è®¤ï¼‰
- `sentence-transformers/all-MiniLM-L6-v2`: 384 ç»´ï¼Œå¿«é€Ÿ
- `BAAI/bge-small-en-v1.5`: 384 ç»´ï¼Œè‹±æ–‡ä¼˜åŒ–

### é˜¶æ®µ 7: åŠ è½½åˆ° LightRAG

```bash
python3 scripts/load_custom_kg_to_lightrag.py \
    --kg output_kg_with_chunks.json \
    --embeddings ./embeddings_gemma \
    --embedding-model google/embeddinggemma-300m
```

**è¾“å…¥**:
- KG with chunks
- Embeddings ç›®å½•

**è¾“å‡º**:
- LightRAG working directory
- åŒ…å«å‘é‡æ•°æ®åº“ã€å›¾å­˜å‚¨ã€KVå­˜å‚¨
- å‡†å¤‡å¥½æ¥å—æŸ¥è¯¢

**å®ç°**:
1. åˆ›å»ºæœ¬åœ° embedding å‡½æ•°ï¼ˆä¸é¢„è®¡ç®—çš„æ¨¡å‹ä¸€è‡´ï¼‰
2. é…ç½® OpenAI API ä½œä¸º LLM
3. åˆå§‹åŒ– LightRAG å®ä¾‹
4. æ’å…¥è‡ªå®šä¹‰ KGï¼ˆä¿ç•™å›¾ç»“æ„ï¼‰
5. ç”Ÿæˆ notebook ç¤ºä¾‹ä»£ç 

### é˜¶æ®µ 8: æŸ¥è¯¢ä¸å¯è§†åŒ–

åœ¨ Jupyter Notebook ä¸­ï¼š

```python
import asyncio
from lightrag import LightRAG, QueryParam

# åˆå§‹åŒ– RAG
rag = LightRAG(
    working_dir="./lightrag_storage",
    embedding_func=embedding_func,
    llm_model_func=llm_func,
)

await rag.initialize_storages()

# æŸ¥è¯¢ç¤ºä¾‹
result = await rag.aquery(
    "What are the POSIX I/O operations?",
    param=QueryParam(mode="hybrid", top_k=5)
)
print(result)
```

**æŸ¥è¯¢æ¨¡å¼**:
- `naive`: ç®€å•å‘é‡æœç´¢
- `local`: åŸºäºå®ä½“çš„å±€éƒ¨æœç´¢ï¼ˆé€‚åˆå…·ä½“ç»†èŠ‚ï¼‰
- `global`: åŸºäºå…³ç³»çš„å…¨å±€æœç´¢ï¼ˆé€‚åˆæ•´ä½“æ¦‚å†µï¼‰
- `hybrid`: local + global ç»“åˆï¼ˆæ¨èï¼‰
- `mix`: æ··åˆå›¾è°±å’Œå‘é‡æ£€ç´¢

---

## æ ¸å¿ƒè„šæœ¬è¯¦è§£

### 1. `scripts/unpack-darshan-logs.sh`

**åŠŸèƒ½**: è§£å‹ Darshan æ—¥å¿— tar.gz æ–‡ä»¶

**è¾“å…¥å‚æ•°**:
- `$1`: çˆ¶ç›®å½•è·¯å¾„ï¼ˆåŒ…å«å¤šä¸ªå­ç›®å½•ï¼Œæ¯ä¸ªå­ç›®å½•æœ‰ `logs.tar.gz`ï¼‰

**è¾“å‡º**:
- è§£å‹åçš„ `.darshan` æ–‡ä»¶ï¼ˆåœ¨åŸåœ°ï¼‰

**å®ç°**:
```bash
# éå†æ‰€æœ‰å­ç›®å½•
find "$PARENT_DIR" -name "logs.tar.gz" | while read tarfile; do
    echo "Extracting: $tarfile"
    tar -xzf "$tarfile" -C "$(dirname "$tarfile")"
    echo "Done: $tarfile"
done
```

**ä½¿ç”¨**:
```bash
chmod +x scripts/unpack-darshan-logs.sh
./scripts/unpack-darshan-logs.sh /path/to/polaris-darshan-logs-25-1/
```

---

### 2. `scripts/process_darshan_signals_v2.4.py`

**åŠŸèƒ½**: ä» Darshan æ–‡æœ¬æ—¥å¿—è®¡ç®—æ´¾ç”Ÿ signals

**è¾“å…¥å‚æ•°**:
- `input_file`: Darshan è§£æåçš„æ–‡æœ¬æ—¥å¿—ï¼ˆå¿…éœ€ï¼‰
- `-o, --output`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º `{input}_signals_v2.4.txt`ï¼‰

**è¾“å‡ºæ ¼å¼**:
```
# ============================================================
# ORIGINAL DARSHAN LOG HEADER
# ============================================================
# darshan log version: 3.41
# jobid: 3122490
# uid: 1449515727
# nprocs: 4
# mount entry: /home lustre
...

# *******************************************************
# JOB LEVEL - Derived Signals
# *******************************************************
JOB	total_bytes_read	7489771.0
JOB	total_bytes_written	11201335.0
JOB	total_reads	910.0
JOB	total_writes	89257.0

# *******************************************************
# POSIX module - Derived Signals
# *******************************************************
POSIX	MODULE_AGG	total_bytes_read	4204115.0
POSIX	MODULE_PERF	read_bw	131.12732077836188

# Record: 11610284057069735693, rank=-1, file=/home/3079452805, mount=/home, fs=lustre
POSIX	-1	11610284057069735693	SIGNAL_READ_START_TS	23.047361
POSIX	-1	11610284057069735693	SIGNAL_READ_END_TS	23.049321
POSIX	-1	11610284057069735693	SIGNAL_READ_BW	131.12732077836188
POSIX	-1	11610284057069735693	SIGNAL_WRITE_BW	NA(no_write_time)
...
```

**å®ç°**:
1. è§£æ headerï¼ˆjobid, uid, nprocs, mount tableï¼‰
2. æå–åŸå§‹ countersï¼ˆPOSIX_OPENS, POSIX_READS, etc.ï¼‰
3. è®¡ç®—ä¸‰å±‚ signals:
   - Job çº§åˆ«: æ±‡æ€»æ‰€æœ‰æ¨¡å—çš„å­—èŠ‚æ•°å’Œæ“ä½œæ•°
   - Module çº§åˆ«: æ¯ä¸ªæ¨¡å—çš„æ€§èƒ½æŒ‡æ ‡ï¼ˆBW, IOPS, avg sizeï¼‰
   - Record çº§åˆ«: 100+ æ´¾ç”ŸæŒ‡æ ‡ï¼ˆè§ä¸‹æ–‡ï¼‰
4. ä½¿ç”¨ `(module, rank, record_id)` ä¸‰å…ƒç»„ä½œä¸ºå”¯ä¸€é”®
5. NA å€¼æ ‡æ³¨åŸå› ï¼š`NA(no_reads)`, `NA(no_write_time)`, etc.

**å…³é”®å‡½æ•°**:
- `parse_log_file()`: è§£ææ—¥å¿—æ–‡ä»¶
- `compute_job_level_signals()`: è®¡ç®— Job çº§åˆ«æ±‡æ€»
- `compute_module_level_signals()`: è®¡ç®— Module çº§åˆ«æ€§èƒ½
- `compute_posix_signals()`: è®¡ç®— POSIX ä¸“ç”¨ signals
- `compute_heatmap_signals()`: è®¡ç®— HEATMAP ä¸“ç”¨ signals

---

### 3. `experiments/darshan_kg_builder_v2.1.py`

**åŠŸèƒ½**: å°† signal æ–‡ä»¶è½¬æ¢ä¸º LightRAG çŸ¥è¯†å›¾è°±

**è¾“å…¥å‚æ•°**:
- `-i, --input`: Signal æ–‡ä»¶æˆ–ç›®å½•ï¼ˆå¿…éœ€ï¼‰
- `-o, --output`: è¾“å‡º KG JSON æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰

**è¾“å‡ºæ ¼å¼**:
```json
{
  "entities": [
    {
      "entity_name": "Job_3122490",
      "entity_type": "JOB",
      "description": "",
      "source_id": "darshan-logs",
      "job_id": 3122490,
      "uid": 1449515727,
      "nprocs": 4,
      "runtime": 7451.1501,
      "total_bytes_read": 7489771.0,
      "mount_table": {"/home": "lustre", ...}
    },
    {
      "entity_name": "3122490::POSIX::11610284057069735693::rank-1",
      "entity_type": "RECORD",
      "description": "",
      "record_id": "11610284057069735693",
      "rank": -1,
      "file_name": "/home/3079452805",
      "read_bw": 131.12732077836188,
      "write_bw": null,
      "write_bw_na_reason": "no_write_time",
      ...
    }
  ],
  "relationships": [
    {
      "src_id": "App_4068766220",
      "tgt_id": "Job_3122490",
      "description": "",
      "keywords": "application job executable",
      "weight": 1.0
    }
  ]
}
```

**å®ç°**:
1. è§£æ signal æ–‡ä»¶çš„ä¸‰å±‚ç»“æ„
2. åˆ›å»º 6 ç§å®ä½“ç±»å‹ï¼ˆAPPLICATION, JOB, MODULE, RECORD, FILE, FILESYSTEMï¼‰
3. åˆ›å»º 6 ç§å…³ç³»ç±»å‹
4. Signal å€¼ç›´æ¥å­˜å‚¨ä¸ºå®ä½“å±æ€§
5. NA å€¼è½¬æ¢ï¼š`NA(reason)` â†’ `null` + `{field}_na_reason` å­—æ®µ
6. å›¾ç»“æ„ç‰¹æ€§:
   - Record = Incidentï¼ˆæœ€å°å¯æ£€ç´¢å•å…ƒï¼‰
   - Signal æ˜¯å±æ€§ï¼ˆéèŠ‚ç‚¹ï¼‰
   - Mount table å­˜å‚¨ä¸º Job å±æ€§
   - FileSystem ä»…è¿æ¥å®é™…è®¿é—®çš„æ–‡ä»¶ç³»ç»Ÿ

**å…³é”®ç±»**:
- `DarshanKGBuilderV2`: ä¸»æ„å»ºå™¨
- `_parse_job_metadata()`: è§£æ job ä¿¡æ¯
- `_parse_module_section()`: è§£ææ¨¡å— section
- `_parse_record_signals()`: è§£æ record signals
- `build_lightrag_kg()`: æ„å»ºæœ€ç»ˆ KG

---

### 4. `scripts/generate_descriptions_v3.py`

**åŠŸèƒ½**: ä¸º KG å®ä½“å’Œå…³ç³»ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°

**è¾“å…¥å‚æ•°**:
- `input_kg.json`: è¾“å…¥ KG æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
- `output_kg.json`: è¾“å‡ºæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰

**è¾“å‡º**:
- æ›´æ–°åçš„ KGï¼ˆæ¯ä¸ªå®ä½“/å…³ç³»çš„ `description` å­—æ®µå·²å¡«å……ï¼‰

**å®ç°**:
1. å®šä¹‰å®ä½“æ¨¡æ¿ï¼ˆAPPLICATION, JOB, MODULE, RECORD, FILE, FILESYSTEMï¼‰
2. å®šä¹‰å…³ç³»æ¨¡æ¿ï¼ˆAPPLICATIONâ†’JOB, JOBâ†’MODULE, etc.ï¼‰
3. å¡«å……æ¨¡æ¿å ä½ç¬¦ï¼ˆå¦‚ `{job_id}`, `{read_bw}`ï¼‰
4. NA å€¼å¤„ç†:
   - å¦‚æœ `read_bw == null` ä¸” `read_bw_na_reason` å­˜åœ¨
   - å¡«å……ä¸ºï¼š`"read bandwidth is unavailable due to {read_bw_na_reason}"`
5. ç»Ÿè®¡æŠ¥å‘Š:
   - æ¨¡æ¿ä¸­æ°¸è¿œæ²¡æœ‰åŒ¹é…åˆ°çš„å±æ€§
   - JSON ä¸­æ°¸è¿œæ²¡æœ‰ç”¨åˆ°çš„å±æ€§
   - æ€»ä½“ä½¿ç”¨æƒ…å†µ

**æ¨¡æ¿ç¤ºä¾‹**ï¼ˆJOBï¼‰:
```python
ENTITY_TEMPLATES["JOB"] = """
This JOB is a single HPC job, describing when it ran, how large it was, and what application it executed.

The job is identified by job_id {job_id} and was submitted by user {uid}.
It ran on {nprocs} processes across {nnodes} compute nodes...
"""
```

---

### 5. `scripts/parse_darshan_chunks.py`

**åŠŸèƒ½**: ä» raw log æå– counter chunks å¹¶æ·»åŠ åˆ° KG

**è¾“å…¥å‚æ•°**:
- `--log`: Raw Darshan log æ–‡ä»¶æˆ–ç›®å½•ï¼ˆå¿…éœ€ï¼‰
- `--kg`: ç°æœ‰ KG JSONï¼ˆå¿…éœ€ï¼‰
- `--output`: è¾“å‡º KG JSONï¼ˆå¯é€‰ï¼Œé»˜è®¤è¦†ç›–åŸæ–‡ä»¶ï¼‰

**è¾“å‡º**:
- æ›´æ–°åçš„ KGï¼ˆåŒ…å« `chunks` æ•°ç»„ï¼‰

**å®ç°**:
1. è§£æ raw log çš„æ‰€æœ‰ counter è¡Œ
2. æŒ‰å®ä½“åç§°åˆ†ç»„:
   - MODULE: `{job_id}::{module_name}`
   - RECORD: `{job_id}::{module}::{record_id}::rank{rank}`
   - FILE: `File_{file_path_norm}`
   - FILESYSTEM: `FS_{fs_type}_{mount_pt}`
3. ä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆ `chunk_text`ï¼ˆåŸå§‹ counter æ–‡æœ¬ï¼‰
4. ç¤ºä¾‹è¾“å‡º:
   ```json
   {
     "chunks": [
       {
         "entity_name": "3122490::POSIX",
         "chunk_text": "POSIX\t-1\t123...\tPOSIX_OPENS\t24\t/home/file\t/home\tlustre\nPOSIX\t-1\t123...\tPOSIX_READS\t100\t..."
       }
     ]
   }
   ```

**å…³é”®å‡½æ•°**:
- `parse_darshan_log()`: è§£æ log æ–‡ä»¶
- `group_by_entity()`: æŒ‰å®ä½“åˆ†ç»„
- `normalize_entity_name()`: æ ‡å‡†åŒ–å®ä½“åç§°

---

### 6. `scripts/embed_kg_local.py`

**åŠŸèƒ½**: ä½¿ç”¨æœ¬åœ° Transformer æ¨¡å‹ç”Ÿæˆ KG embeddings

**è¾“å…¥å‚æ•°**:
- `--kg`: KG JSON æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
- `--output`: è¾“å‡ºç›®å½•ï¼ˆå¿…éœ€ï¼‰
- `--model`: Hugging Face æ¨¡å‹åç§°ï¼ˆé»˜è®¤ `google/embeddinggemma-300m`ï¼‰
- `--batch-size`: Batch å¤§å°ï¼ˆé»˜è®¤ 32ï¼‰
- `--max-length`: æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤ 512ï¼‰
- `--device`: è®¾å¤‡ï¼ˆ`cpu` æˆ– `cuda`ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰

**è¾“å‡º**:
- `entity_embeddings.pkl`: å®ä½“å‘é‡å­—å…¸
- `relationship_embeddings.pkl`: å…³ç³»å‘é‡å­—å…¸
- `entity_embeddings.npy`: NumPy æ•°ç»„æ ¼å¼
- `relationship_embeddings.npy`: NumPy æ•°ç»„æ ¼å¼
- `embedding_metadata.json`: å…ƒæ•°æ®

**å®ç°**:
1. åŠ è½½ Hugging Face Transformer æ¨¡å‹
2. å®ä½“æ–‡æœ¬ = `"{entity_name}: {description}"`
3. å…³ç³»æ–‡æœ¬ = `"{src_id} -> {tgt_id}: {description}"`
4. Tokenize + Encode
5. Mean poolingï¼ˆä½¿ç”¨ attention maskï¼‰
6. L2 normalization
7. Batch å¤„ç†ï¼ˆé¿å… OOMï¼‰
8. ä¿å­˜ä¸º pickle å’Œ numpy

**å…³é”®å‡½æ•°**:
- `embed_texts()`: Batch embedding
- `mean_pooling()`: å¹³å‡æ± åŒ–
- `prepare_entity_texts()`: å‡†å¤‡å®ä½“æ–‡æœ¬
- `prepare_relationship_texts()`: å‡†å¤‡å…³ç³»æ–‡æœ¬

**æ¨èæ¨¡å‹å¯¹æ¯”**:

| æ¨¡å‹ | ç»´åº¦ | å¤§å° | é€Ÿåº¦ | ç²¾åº¦ | æ¨èåœºæ™¯ |
|------|------|------|------|------|----------|
| google/embeddinggemma-300m | 768 | 1.2GB | ä¸­ | é«˜ | é»˜è®¤æ¨è âœ… |
| sentence-transformers/all-MiniLM-L6-v2 | 384 | 80MB | å¿« | ä¸­ | å¿«é€Ÿæµ‹è¯• |
| BAAI/bge-small-en-v1.5 | 384 | 130MB | å¿« | é«˜ | è‹±æ–‡ä»»åŠ¡ |
| BAAI/bge-m3 | 1024 | 2.5GB | æ…¢ | å¾ˆé«˜ | å¤šè¯­è¨€é«˜ç²¾åº¦ |

---

### 7. `scripts/embed_kg_cpu_optimized.sh`

**åŠŸèƒ½**: CPU ä¼˜åŒ–çš„å¿«é€Ÿ embedding è„šæœ¬

**è¾“å…¥**:
- ç¡¬ç¼–ç  KG è·¯å¾„ï¼ˆå¯ä¿®æ”¹è„šæœ¬ï¼‰

**è¾“å‡º**:
- `./embeddings_cpu/` ç›®å½•
- ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼ˆ`all-MiniLM-L6-v2`ï¼‰

**å®ç°**:
```bash
python3 embed_kg_local.py \
  --kg "$KG_FILE" \
  --output "$OUTPUT_DIR" \
  --model sentence-transformers/all-MiniLM-L6-v2 \
  --batch-size 4 \
  --max-length 2048
```

**ä¼˜åŒ–**:
- Batch size = 4ï¼ˆCPU å‹å¥½ï¼‰
- ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼ˆ80MBï¼‰
- Max length = 2048ï¼ˆæ”¯æŒé•¿æ–‡æœ¬ï¼‰

---

### 8. `scripts/load_custom_kg_to_lightrag.py`

**åŠŸèƒ½**: å°† KG å’Œ embeddings åŠ è½½åˆ° LightRAG

**è¾“å…¥å‚æ•°**:
- `--kg`: KG JSON æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
- `--embeddings`: Embeddings ç›®å½•ï¼ˆå¯é€‰ï¼‰
- `--embedding-model`: Embedding æ¨¡å‹åç§°ï¼ˆé»˜è®¤ `sentence-transformers/all-MiniLM-L6-v2`ï¼‰
- `--working-dir`: LightRAG working directoryï¼ˆé»˜è®¤ `./lightrag_darshan_storage`ï¼‰
- `--openai-key`: OpenAI API keyï¼ˆå¯é€‰ï¼Œæˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡ `OPENAI_API_KEY`ï¼‰
- `--openai-model`: OpenAI æ¨¡å‹ï¼ˆé»˜è®¤ `gpt-4o-mini`ï¼‰

**è¾“å‡º**:
- LightRAG working directoryï¼ˆåŒ…å«å‘é‡æ•°æ®åº“ã€å›¾å­˜å‚¨ï¼‰
- Notebook ç¤ºä¾‹ä»£ç ï¼ˆæ‰“å°åˆ°æ§åˆ¶å°ï¼‰

**å®ç°**:
1. åˆ›å»ºæœ¬åœ° embedding å‡½æ•°ï¼ˆä¸é¢„è®¡ç®—æ¨¡å‹ä¸€è‡´ï¼‰
2. é…ç½® OpenAI API
3. åˆå§‹åŒ– LightRAG å®ä¾‹
4. æ’å…¥è‡ªå®šä¹‰ KGï¼š
   - å®ä½“ â†’ å‘é‡æ•°æ®åº“
   - å…³ç³» â†’ å›¾å­˜å‚¨
   - Chunks â†’ æ–‡æœ¬ç´¢å¼•
5. ç”Ÿæˆ notebook ä»£ç ç¤ºä¾‹

**å…³é”®ç±»**:
- `LocalEmbeddingFunction`: æœ¬åœ° embedding wrapper
- `llm_model_func`: OpenAI LLM wrapper
- LightRAG é…ç½®

---

## Signal è®¡ç®—è§„æ ¼

### æ¦‚è¿°

Signals åˆ†ä¸ºä¸‰å±‚ï¼š
1. **Job Level**: ä½œä¸šçº§åˆ«æ±‡æ€»ï¼ˆ4 ä¸ªï¼‰
2. **Module Level**: æ¨¡å—çº§åˆ«æ€§èƒ½ï¼ˆ6 ä¸ª/æ¨¡å—ï¼‰
3. **Record Level**: è®°å½•çº§åˆ«è¯¦ç»†æŒ‡æ ‡ï¼ˆ100+/è®°å½•ï¼‰

### NA å€¼åŸå› æ ‡æ³¨

æ‰€æœ‰ NA å€¼æ ¼å¼ï¼š`NA(reason)`

| åŸå› ä»£ç  | å«ä¹‰ | ç¤ºä¾‹ |
|---------|------|------|
| `no_reads` | è¯»æ“ä½œæ•°ä¸º0 | `avg_read_size = NA(no_reads)` |
| `no_writes` | å†™æ“ä½œæ•°ä¸º0 | `avg_write_size = NA(no_writes)` |
| `no_io` | æ— I/Oæ“ä½œ | `seq_ratio = NA(no_io)` |
| `no_read_time` | è¯»æ—¶é—´ä¸º0 | `read_bw = NA(no_read_time)` |
| `no_write_time` | å†™æ—¶é—´ä¸º0 | `write_bw = NA(no_write_time)` |
| `no_time` | æ€»æ—¶é—´ä¸º0 | `read_iops = NA(no_time)` |
| `no_bytes` | å­—èŠ‚æ•°ä¸º0 | `rank_imbalance_ratio = NA(no_bytes)` |
| `not_shared_file` | rank != -1ï¼Œéå…±äº«æ–‡ä»¶ | `rank_imbalance_ratio = NA(not_shared_file)` |
| `no_bin_width` | HEATMAP ç¼ºå°‘ bin width | HEATMAP signal = `NA(no_bin_width)` |

---

### 1. Job Level Signals

| Signal | å…¬å¼ | è¯´æ˜ |
|--------|------|------|
| `total_bytes_read` | Î£(æ‰€æœ‰æ¨¡å—çš„ bytes_read) | ä½œä¸šæ€»è¯»å­—èŠ‚æ•° |
| `total_bytes_written` | Î£(æ‰€æœ‰æ¨¡å—çš„ bytes_written) | ä½œä¸šæ€»å†™å­—èŠ‚æ•° |
| `total_reads` | Î£(æ‰€æœ‰æ¨¡å—çš„ reads) | ä½œä¸šæ€»è¯»æ“ä½œæ•° |
| `total_writes` | Î£(æ‰€æœ‰æ¨¡å—çš„ writes) | ä½œä¸šæ€»å†™æ“ä½œæ•° |

---

### 2. Module Level Signals

æ¯ä¸ªæ¨¡å—ï¼ˆPOSIX, STDIO, MPIIOï¼‰è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡ï¼š

| Signal | å…¬å¼ | NA åŸå›  |
|--------|------|--------|
| `total_bytes_read` | Î£(è¯¥æ¨¡å—æ‰€æœ‰ records çš„ bytes_read) | - |
| `total_bytes_written` | Î£(è¯¥æ¨¡å—æ‰€æœ‰ records çš„ bytes_written) | - |
| `total_reads` | Î£(è¯¥æ¨¡å—æ‰€æœ‰ records çš„ reads) | - |
| `total_writes` | Î£(è¯¥æ¨¡å—æ‰€æœ‰ records çš„ writes) | - |
| `read_bw` | total_bytes_read / 1024Â² / total_time | `NA(no_time)` |
| `write_bw` | total_bytes_written / 1024Â² / total_time | `NA(no_time)` |
| `read_iops` | total_reads / total_time | `NA(no_time)` |
| `write_iops` | total_writes / total_time | `NA(no_time)` |
| `avg_read_size` | total_bytes_read / total_reads | `NA(no_reads)` |
| `avg_write_size` | total_bytes_written / total_writes | `NA(no_writes)` |

**æ³¨æ„**: HEATMAP æ¨¡å—ä¸è®¡ç®— MODULE_AGG å’Œ MODULE_PERFï¼ˆæ— æ„ä¹‰ï¼‰

---

### 3. Record Level Signals

#### 3.1 é€šç”¨ Signalsï¼ˆæ‰€æœ‰æ¨¡å—ï¼‰

##### æ—¶é—´æŒ‡æ ‡

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `read_start_ts` | `F_READ_START_TIMESTAMP` | ç¬¬ä¸€æ¬¡è¯»æ“ä½œçš„æ—¶é—´æˆ³ | `NA(not_monitored)` |
| `read_end_ts` | `F_READ_END_TIMESTAMP` | æœ€åä¸€æ¬¡è¯»æ“ä½œçš„æ—¶é—´æˆ³ | `NA(not_monitored)` |
| `write_start_ts` | `F_WRITE_START_TIMESTAMP` | ç¬¬ä¸€æ¬¡å†™æ“ä½œçš„æ—¶é—´æˆ³ | `NA(not_monitored)` |
| `write_end_ts` | `F_WRITE_END_TIMESTAMP` | æœ€åä¸€æ¬¡å†™æ“ä½œçš„æ—¶é—´æˆ³ | `NA(not_monitored)` |
| `meta_start_ts` | `F_META_START_TIMESTAMP` | ç¬¬ä¸€æ¬¡å…ƒæ•°æ®æ“ä½œæ—¶é—´æˆ³ | `NA(not_monitored)` |
| `meta_end_ts` | `F_META_END_TIMESTAMP` | æœ€åä¸€æ¬¡å…ƒæ•°æ®æ“ä½œæ—¶é—´æˆ³ | `NA(not_monitored)` |
| `read_time` | `F_READ_TIME` | ç´¯è®¡è¯»æ—¶é—´ï¼ˆç§’ï¼‰ | - |
| `write_time` | `F_WRITE_TIME` | ç´¯è®¡å†™æ—¶é—´ï¼ˆç§’ï¼‰ | - |
| `meta_time` | `F_META_TIME` | ç´¯è®¡å…ƒæ•°æ®æ“ä½œæ—¶é—´ï¼ˆç§’ï¼‰ | - |
| `io_time` | read_time + write_time | æ€» I/O æ—¶é—´ | - |
| `read_span` | read_end_ts - read_start_ts | è¯»æ“ä½œæ—¶é—´è·¨åº¦ | - |
| `write_span` | write_end_ts - write_start_ts | å†™æ“ä½œæ—¶é—´è·¨åº¦ | - |
| `meta_span` | meta_end_ts - meta_start_ts | å…ƒæ•°æ®æ“ä½œæ—¶é—´è·¨åº¦ | - |
| `io_span` | max(read_end_ts, write_end_ts, meta_end_ts) - min(...) | æ€» I/O æ—¶é—´è·¨åº¦ | - |
| `read_busy_frac` | read_time / read_span | è¯»æ“ä½œå¿™ç¢Œæ¯”ä¾‹ | `NA(no_read_time)` |
| `write_busy_frac` | write_time / write_span | å†™æ“ä½œå¿™ç¢Œæ¯”ä¾‹ | `NA(no_write_time)` |
| `meta_busy_frac` | meta_time / meta_span | å…ƒæ•°æ®æ“ä½œå¿™ç¢Œæ¯”ä¾‹ | `NA(no_meta_time)` |
| `busy_frac` | io_time / io_span | æ€» I/O å¿™ç¢Œæ¯”ä¾‹ | - |

##### æ€§èƒ½æŒ‡æ ‡

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `read_bw` | bytes_read / 1024Â² / read_time | è¯»å¸¦å®½ï¼ˆMB/sï¼‰ | `NA(no_read_time)` |
| `write_bw` | bytes_written / 1024Â² / write_time | å†™å¸¦å®½ï¼ˆMB/sï¼‰ | `NA(no_write_time)` |
| `read_iops` | reads / read_time | è¯» IOPSï¼ˆæ“ä½œ/ç§’ï¼‰ | `NA(no_read_time)` |
| `write_iops` | writes / write_time | å†™ IOPSï¼ˆæ“ä½œ/ç§’ï¼‰ | `NA(no_write_time)` |
| `avg_read_size` | bytes_read / reads | å¹³å‡è¯»å¤§å°ï¼ˆå­—èŠ‚ï¼‰ | `NA(no_reads)` |
| `avg_write_size` | bytes_written / writes | å¹³å‡å†™å¤§å°ï¼ˆå­—èŠ‚ï¼‰ | `NA(no_writes)` |
| `avg_read_lat` | read_time / reads | å¹³å‡è¯»å»¶è¿Ÿï¼ˆç§’ï¼‰ | `NA(no_reads)` |
| `avg_write_lat` | write_time / writes | å¹³å‡å†™å»¶è¿Ÿï¼ˆç§’ï¼‰ | `NA(no_writes)` |
| `max_read_time` | `F_MAX_READ_TIME` | æœ€å¤§å•æ¬¡è¯»æ—¶é—´ | - |
| `max_write_time` | `F_MAX_WRITE_TIME` | æœ€å¤§å•æ¬¡å†™æ—¶é—´ | - |
| `max_read_time_size` | `F_MAX_READ_TIME_SIZE` | æœ€å¤§è¯»æ—¶é—´å¯¹åº”çš„å¤§å° | - |
| `max_write_time_size` | `F_MAX_WRITE_TIME_SIZE` | æœ€å¤§å†™æ—¶é—´å¯¹åº”çš„å¤§å° | - |

##### æ•°æ®é‡æŒ‡æ ‡

| Signal | å…¬å¼ | è¯´æ˜ |
|--------|------|------|
| `bytes_read` | `BYTES_READ` | è¯»å–å­—èŠ‚æ•° |
| `bytes_written` | `BYTES_WRITTEN` | å†™å…¥å­—èŠ‚æ•° |
| `reads` | `READS` | è¯»æ“ä½œæ•° |
| `writes` | `WRITES` | å†™æ“ä½œæ•° |

---

#### 3.2 POSIX ä¸“ç”¨ Signals

##### è®¿é—®æ¨¡å¼

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `seq_read_ratio` | `SEQ_READS` / reads | é¡ºåºè¯»æ¯”ä¾‹ | `NA(no_reads)` |
| `seq_write_ratio` | `SEQ_WRITES` / writes | é¡ºåºå†™æ¯”ä¾‹ | `NA(no_writes)` |
| `consec_read_ratio` | `CONSEC_READS` / reads | è¿ç»­è¯»æ¯”ä¾‹ | `NA(no_reads)` |
| `consec_write_ratio` | `CONSEC_WRITES` / writes | è¿ç»­å†™æ¯”ä¾‹ | `NA(no_writes)` |
| `seq_ratio` | (SEQ_READS + SEQ_WRITES) / (reads + writes) | æ€»é¡ºåºè®¿é—®æ¯”ä¾‹ | `NA(no_io)` |
| `consec_ratio` | (CONSEC_READS + CONSEC_WRITES) / (reads + writes) | æ€»è¿ç»­è®¿é—®æ¯”ä¾‹ | `NA(no_io)` |
| `rw_switches` | `RW_SWITCHES` | è¯»å†™åˆ‡æ¢æ¬¡æ•° | - |

##### å…ƒæ•°æ®æ“ä½œ

| Signal | å…¬å¼ | è¯´æ˜ |
|--------|------|------|
| `meta_ops` | OPENS + STATS + SEEKS + FSYNCS + FDSYNCS | å…ƒæ•°æ®æ“ä½œæ€»æ•° |
| `meta_intensity` | meta_ops / (reads + writes) | å…ƒæ•°æ®å¼ºåº¦ |
| `meta_fraction` | meta_time / io_time | å…ƒæ•°æ®æ—¶é—´å æ¯” |

##### å¯¹é½å’Œå¤§å°

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `unaligned_read_ratio` | `MEM_NOT_ALIGNED` / reads | æœªå¯¹é½è¯»æ¯”ä¾‹ | `NA(no_reads)` |
| `unaligned_write_ratio` | `MEM_NOT_ALIGNED` / writes | æœªå¯¹é½å†™æ¯”ä¾‹ | `NA(no_writes)` |
| `small_read_ratio` | `SIZE_READ_0_100` / reads | å°è¯»ï¼ˆ<100Bï¼‰æ¯”ä¾‹ | `NA(no_reads)` |
| `small_write_ratio` | `SIZE_WRITE_0_100` / writes | å°å†™ï¼ˆ<100Bï¼‰æ¯”ä¾‹ | `NA(no_writes)` |
| `tail_read_ratio` | æœ€å¤§çš„ SIZE_READ_bin / reads | å¤§è¯»æ¯”ä¾‹ | `NA(no_reads)` |
| `tail_write_ratio` | æœ€å¤§çš„ SIZE_WRITE_bin / writes | å¤§å†™æ¯”ä¾‹ | `NA(no_writes)` |

##### æ•°æ®é‡ç”¨

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `reuse_proxy` | bytes_read / (MAX_BYTE_READ + 1) | æ•°æ®é‡ç”¨ä»£ç† | `NA(no_file_size)` |

##### Rank ä¸å‡è¡¡ï¼ˆä»…å…±äº«æ–‡ä»¶ï¼Œrank=-1ï¼‰

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `rank_imbalance_ratio` | `F_SLOWEST_RANK_BYTES` / `F_FASTEST_RANK_BYTES` | Rank å­—èŠ‚ä¸å‡è¡¡æ¯”ä¾‹ | `NA(not_shared_file)` æˆ– `NA(no_fastest_bytes)` |
| `rank_time_imb` | (`F_SLOWEST_RANK_TIME` - `F_FASTEST_RANK_TIME`) / `F_FASTEST_RANK_TIME` | Rank æ—¶é—´ä¸å‡è¡¡ | `NA(not_shared_file)` |
| `fastest_rank_time` | `F_FASTEST_RANK_TIME` | æœ€å¿« rank çš„æ—¶é—´ | `NA(not_shared_file)` |
| `slowest_rank_time` | `F_SLOWEST_RANK_TIME` | æœ€æ…¢ rank çš„æ—¶é—´ | `NA(not_shared_file)` |
| `var_rank_time` | `F_VARIANCE_RANK_TIME` | Rank æ—¶é—´æ–¹å·® | `NA(not_shared_file)` |
| `var_rank_bytes` | `F_VARIANCE_RANK_BYTES` | Rank å­—èŠ‚æ–¹å·® | `NA(not_shared_file)` |
| `bw_variance_proxy` | var_rank_bytes | å¸¦å®½æ–¹å·®ä»£ç† | `NA(not_shared_file)` |

##### å…¶ä»–

| Signal | è¯´æ˜ |
|--------|------|
| `is_shared` | 1 if rank=-1 else 0ï¼ˆæ˜¯å¦ä¸ºå…±äº«æ–‡ä»¶ï¼‰ |

---

#### 3.3 HEATMAP ä¸“ç”¨ Signals

HEATMAP æ¨¡å—è®°å½• I/O æ´»åŠ¨çš„æ—¶é—´åˆ†å¸ƒï¼Œä½¿ç”¨ bins ç»Ÿè®¡ä¸åŒæ—¶é—´æ®µçš„ I/O äº‹ä»¶ã€‚

##### è¾“å…¥æ•°æ®

- `HEATMAP_F_BIN_WIDTH_SECONDS`: æ¯ä¸ª bin çš„æ—¶é—´å®½åº¦ï¼ˆÎ”tï¼‰
- `HEATMAP_READ_BIN_k`: ç¬¬ k ä¸ª bin çš„è¯»äº‹ä»¶æ•°ï¼ˆR[k]ï¼‰
- `HEATMAP_WRITE_BIN_k`: ç¬¬ k ä¸ª bin çš„å†™äº‹ä»¶æ•°ï¼ˆW[k]ï¼‰
- k = 0, 1, 2, ..., N-1ï¼ˆN ä¸º bin æ€»æ•°ï¼‰

##### å®šä¹‰

è®¾ï¼š
- Î”t = `HEATMAP_F_BIN_WIDTH_SECONDS`
- R[k] = `HEATMAP_READ_BIN_k`
- W[k] = `HEATMAP_WRITE_BIN_k`
- A[k] = R[k] + W[k]ï¼ˆæ€»æ´»åŠ¨ï¼‰
- N = bin æ€»æ•°

##### è®¡ç®—çš„ Signals

| Signal | å…¬å¼ | è¯´æ˜ | NA åŸå›  |
|--------|------|------|--------|
| `total_read_events` | Î£ R[k] | æ‰€æœ‰ bin çš„è¯»äº‹ä»¶æ€»æ•° | - |
| `total_write_events` | Î£ W[k] | æ‰€æœ‰ bin çš„å†™äº‹ä»¶æ€»æ•° | - |
| `active_bins` | \|{k \| A[k]>0}\| | æœ‰æ´»åŠ¨çš„ bin æ•°é‡ | - |
| `active_time` | active_bins Ã— Î”t | æœ‰ I/O æ´»åŠ¨çš„æ€»æ—¶é—´ï¼ˆç§’ï¼‰ | `NA(no_bin_width)` |
| `activity_span` | (k_last - k_first + 1) Ã— Î”t | ä»ç¬¬ä¸€ä¸ªåˆ°æœ€åä¸€ä¸ªæ´»åŠ¨ bin çš„æ—¶é—´è·¨åº¦ | `NA(no_bin_width)` |
| `peak_activity_bin` | argmax_k A[k] | æ´»åŠ¨æœ€å¯†é›†çš„ bin çš„**ç´¢å¼•**ï¼ˆ0-Nï¼‰ | - |
| `peak_activity_value` | max A[k] | æ´»åŠ¨æœ€å¯†é›†çš„ bin çš„**äº‹ä»¶æ•°** | - |
| `read_activity_entropy_norm` | H_r^{norm} | è¯»æ´»åŠ¨åˆ†å¸ƒçš„å½’ä¸€åŒ–ç†µ [0,1] | - |
| `write_activity_entropy_norm` | H_w^{norm} | å†™æ´»åŠ¨åˆ†å¸ƒçš„å½’ä¸€åŒ–ç†µ [0,1] | - |
| `top1_share` | max A[k] / Î£ A[k] | æœ€å¤§ bin å æ€»æ´»åŠ¨çš„æ¯”ä¾‹ | - |

##### è¯¦ç»†å…¬å¼

**1. total_read_events**
```
TR = Î£_{k=0}^{N-1} R[k]
```

**2. total_write_events**
```
TW = Î£_{k=0}^{N-1} W[k]
```

**3. active_bins**
```
N_active = |{k | A[k] > 0}|
```

**4. active_time**
```
T_active = N_active Ã— Î”t
```

**5. activity_span**
```
k_first = min{k | A[k] > 0}
k_last = max{k | A[k] > 0}
T_span = (k_last - k_first + 1) Ã— Î”t
```

**6. peak_activity_bin**
è¿”å›æ´»åŠ¨æœ€å¯†é›†çš„ bin çš„**ç´¢å¼•**ï¼ˆ0-Nï¼‰ï¼š
```
peak_idx = argmax_{k} A[k]
```

**7. peak_activity_value**
è¿”å›æ´»åŠ¨æœ€å¯†é›†çš„ bin çš„**äº‹ä»¶æ•°**ï¼š
```
A_peak = max_{k} A[k]
```

**8. read_activity_entropy_norm**
è¯»åˆ†å¸ƒçš„å½’ä¸€åŒ–ç†µï¼š
```
è‹¥ TR > 0:
  p_k = R[k] / TR  (å¯¹æ‰€æœ‰ k)
  H_r = -Î£_{k: p_k>0} p_k Ã— log(p_k)
  H_r^{norm} = H_r / log(N)
å¦åˆ™:
  H_r^{norm} = 0
```

**è§£é‡Š**ï¼š
- ç†µå€¼è¶Šé«˜ï¼Œè¯»æ´»åŠ¨åœ¨æ—¶é—´ä¸Šåˆ†å¸ƒè¶Šå‡åŒ€
- ç†µå€¼è¶Šä½ï¼Œè¯»æ´»åŠ¨è¶Šé›†ä¸­åœ¨å°‘æ•°æ—¶é—´æ®µ
- å½’ä¸€åŒ–åˆ° [0,1]ï¼Œä¾¿äºæ¯”è¾ƒ

**9. write_activity_entropy_norm**
å†™åˆ†å¸ƒçš„å½’ä¸€åŒ–ç†µï¼ˆå…¬å¼åŒä¸Šï¼Œä½¿ç”¨ W[k]ï¼‰

**10. top1_share**
æœ€å¤§ bin å æ¯”ï¼ˆåæ˜  I/O çªå‘æ€§ï¼‰ï¼š
```
TA = Î£_{k} A[k]
è‹¥ TA > 0:
  S_1 = max_{k} A[k] / TA
å¦åˆ™:
  S_1 = 0
```

**è§£é‡Š**ï¼š
- æ¥è¿‘ 1ï¼šI/O é«˜åº¦é›†ä¸­åœ¨æŸä¸ªæ—¶é—´æ®µï¼ˆçªå‘æ€§å¼ºï¼‰
- æ¥è¿‘ 0ï¼šI/O å‡åŒ€åˆ†å¸ƒåœ¨å¤šä¸ªæ—¶é—´æ®µ

##### HEATMAP Signals çš„æ„ä¹‰

| Signal | ç”¨é€” | å¼‚å¸¸æŒ‡ç¤º |
|--------|------|----------|
| `active_time` | å®é™… I/O æ´»è·ƒæ—¶é—´ | ä¸ runtime å¯¹æ¯”ï¼Œè¯†åˆ« I/O ç¨€ç–æ€§ |
| `activity_span` | I/O æ—¶é—´è·¨åº¦ | è¯†åˆ« I/O æ˜¯å¦åˆ†æ•£åœ¨æ•´ä¸ªä½œä¸šå‘¨æœŸ |
| `entropy_norm` | æ—¶é—´åˆ†å¸ƒå‡åŒ€æ€§ | ä½ç†µ â†’ I/O é›†ä¸­ï¼ˆå¯èƒ½æ˜¯æ£€æŸ¥ç‚¹ï¼‰ |
| `top1_share` | çªå‘æ€§ | é«˜å€¼ â†’ çŸ­æ—¶é—´å¤§é‡ I/Oï¼ˆçªå‘ï¼‰ |
| `peak_activity_bin` | å³°å€¼ I/O å¼ºåº¦ | è¯†åˆ« I/O ç“¶é¢ˆæ—¶åˆ» |

---

### 4. Signal æ€»ç»“è¡¨ï¼ˆæŒ‰ç±»åˆ«ï¼‰

#### æ—¶é—´ç±»ï¼ˆ21 ä¸ªï¼‰

| ç±»åˆ« | Signals |
|------|---------|
| æ—¶é—´æˆ³ | `read_start_ts`, `read_end_ts`, `write_start_ts`, `write_end_ts`, `meta_start_ts`, `meta_end_ts` |
| ç´¯è®¡æ—¶é—´ | `read_time`, `write_time`, `meta_time`, `io_time` |
| æ—¶é—´è·¨åº¦ | `read_span`, `write_span`, `meta_span`, `io_span` |
| å¿™ç¢Œæ¯”ä¾‹ | `read_busy_frac`, `write_busy_frac`, `meta_busy_frac`, `busy_frac` |
| å»¶è¿Ÿ | `avg_read_lat`, `avg_write_lat`, `max_read_time`, `max_write_time` |

#### æ€§èƒ½ç±»ï¼ˆ12 ä¸ªï¼‰

| ç±»åˆ« | Signals |
|------|---------|
| å¸¦å®½ | `read_bw`, `write_bw` |
| IOPS | `read_iops`, `write_iops` |
| æ“ä½œå¤§å° | `avg_read_size`, `avg_write_size`, `max_read_time_size`, `max_write_time_size` |
| æ•°æ®é‡ | `bytes_read`, `bytes_written`, `reads`, `writes` |

#### è®¿é—®æ¨¡å¼ç±»ï¼ˆ15 ä¸ªï¼‰

| ç±»åˆ« | Signals |
|------|---------|
| é¡ºåºæ€§ | `seq_read_ratio`, `seq_write_ratio`, `seq_ratio` |
| è¿ç»­æ€§ | `consec_read_ratio`, `consec_write_ratio`, `consec_ratio` |
| è¯»å†™åˆ‡æ¢ | `rw_switches` |
| å¯¹é½ | `unaligned_read_ratio`, `unaligned_write_ratio` |
| å¤§å°åˆ†å¸ƒ | `small_read_ratio`, `small_write_ratio`, `tail_read_ratio`, `tail_write_ratio` |
| æ•°æ®é‡ç”¨ | `reuse_proxy` |
| å…±äº«æ€§ | `is_shared` |

#### å…ƒæ•°æ®ç±»ï¼ˆ3 ä¸ªï¼‰

| Signals |
|---------|
| `meta_ops`, `meta_intensity`, `meta_fraction` |

#### Rank ä¸å‡è¡¡ç±»ï¼ˆ7 ä¸ªï¼‰

| Signals |
|---------|
| `rank_imbalance_ratio`, `rank_time_imb`, `fastest_rank_time`, `slowest_rank_time`, `var_rank_time`, `var_rank_bytes`, `bw_variance_proxy` |

#### HEATMAP æ—¶é—´åˆ†å¸ƒç±»ï¼ˆ10 ä¸ªï¼‰

| Signals |
|---------|
| `total_read_events`, `total_write_events`, `active_bins`, `active_time`, `activity_span`, `peak_activity_bin`, `peak_activity_value`, `read_activity_entropy_norm`, `write_activity_entropy_norm`, `top1_share` |

---

## è®¾è®¡æ€è·¯

### æ ¸å¿ƒåŸåˆ™

1. **Record = Incident = æœ€å°å¯æ£€ç´¢å•å…ƒ**
   - æ¯ä¸ª Darshan record å¯¹åº”ä¸€ä¸ª incident å®ä½“
   - æ‰€æœ‰ signal å€¼ä½œä¸ºè¯¥å®ä½“çš„å±æ€§å­˜å‚¨ï¼ˆè€Œéç‹¬ç«‹èŠ‚ç‚¹ï¼‰
   - æ”¯æŒ incident çº§æ£€ç´¢ï¼šç”¨æˆ·æŸ¥è¯¢èšç„¦äº"å“ªäº› incident çš„å¸¦å®½é«˜äº X"

2. **æ”¯æŒä¸‹æ¸¸è®¡ç®—**
   - ä¿ç•™åŸå§‹ signal å€¼ç”¨äºèšåˆè®¡ç®—ï¼ˆå¹³å‡ã€æœ€å¤§å€¼ã€ç™¾åˆ†ä½ç­‰ï¼‰
   - ä¸æŸå¤±æ•°æ®ç²¾åº¦

3. **å¯è§£é‡Šæ€§**
   - å›¾è¾¹è¿æ¥è¡¨ç¤ºå¯æ¯”æ€§ï¼ˆç›¸åŒåº”ç”¨/æ–‡ä»¶ç³»ç»Ÿ/æ¨¡å—ï¼‰
   - è€Œéä¿¡å·ç›¸ä¼¼åº¦
   - æ¯ä¸ªå®ä½“æœ‰è‡ªç„¶è¯­è¨€æè¿°

4. **å¯æ‰©å±•æ€§**
   - é¿å…äº§ç”Ÿæ•°ç™¾ä¸‡ä¸ª signal èŠ‚ç‚¹
   - ä¿æŒå›¾è§„æ¨¡å¯æ§ï¼ˆå®ä½“æ•° = åº”ç”¨æ•° + ä½œä¸šæ•° + æ¨¡å—æ•° + è®°å½•æ•° + æ–‡ä»¶æ•° + æ–‡ä»¶ç³»ç»Ÿæ•°ï¼‰

### å…³é”®è®¾è®¡å†³ç­–

#### 1. NA å€¼å¤„ç†

- **æ•°å€¼å­—æ®µ**: ç¼ºå¤±å€¼ç»Ÿä¸€ç”¨ `null` è¡¨ç¤ºï¼ˆè€Œéå­—ç¬¦ä¸² "NA(...)"ï¼‰
- **åŸå› å­—æ®µ**: æ·»åŠ å¹¶è¡Œå­—æ®µ `{field_name}_na_reason` è¯´æ˜ç¼ºå¤±åŸå› 
- **ç¤ºä¾‹**:
  ```json
  {
    "read_bw": null,
    "read_bw_na_reason": "no_time"
  }
  ```
- **ä¼˜åŠ¿**: ä¾¿äºä¸‹æ¸¸æ•°å€¼è®¡ç®—å’Œè¿‡æ»¤

#### 2. Mount Table ä½œä¸º Job å±æ€§

- **è®¾è®¡**: mount table å­˜å‚¨ä¸º Job å®ä½“çš„ `mount_table` å±æ€§
- **æ ¼å¼**: `{mount_pt: fs_type}` å­—å…¸
- **ä¸åˆ›å»ºè¾¹**: é¿å… Job è¿æ¥æ‰€æœ‰ç³»ç»Ÿä¸­å­˜åœ¨çš„ filesystem
- **Rationale**: mount table æ˜¯ç³»ç»Ÿé…ç½®ï¼Œä¸æ˜¯ I/O è¡Œä¸º

#### 3. Job â†’ FileSystem è¾¹

- **è¾¹åç§°**: `TOUCH_FILESYSTEM`
- **åˆ›å»ºæ¡ä»¶**: ä»…è¿æ¥ records ä¸­**å®é™…è®¿é—®è¿‡**çš„ filesystem
- **Rationale**: åæ˜ çœŸå® I/O è¡Œä¸ºï¼Œè€Œéç³»ç»Ÿé…ç½®

#### 4. Signal å‘½åç©ºé—´éš”ç¦»

- **é—®é¢˜**: åŒä¸€ record_id å¯èƒ½åœ¨å¤šä¸ª module ä¸­å‡ºç°ï¼ˆå¦‚ HEATMAP å’Œ POSIXï¼‰
- **è§£å†³**: ä¸¥æ ¼é™åˆ¶æ¯ä¸ª module section åªè§£æè¯¥ section å†…çš„ records
- **ç»“æœ**: HEATMAP records åªåŒ…å« HEATMAP signalsï¼ŒPOSIX records åªåŒ…å« POSIX signals

#### 5. ä¸‰å±‚å±‚æ¬¡åŒ–ç»“æ„

- **Job Level**: ä½œä¸šçº§åˆ«æ±‡æ€»ï¼ˆå…¨å±€è§†å›¾ï¼‰
- **Module Level**: æ¨¡å—çº§åˆ«æ€§èƒ½ï¼ˆæ¥å£å±‚è§†å›¾ï¼‰
- **Record Level**: è®°å½•çº§åˆ«è¯¦ç»†æŒ‡æ ‡ï¼ˆæ–‡ä»¶çº§è§†å›¾ï¼‰

**ä¼˜åŠ¿**:
- æ”¯æŒå¤šç²’åº¦æŸ¥è¯¢
- ä¾¿äºèšåˆè®¡ç®—
- ä¿æŒæ•°æ®å±‚æ¬¡æ€§

#### 6. Description æ¨¡æ¿ç³»ç»Ÿ

- **å®ä½“æ¨¡æ¿**: é’ˆå¯¹æ¯ç§å®ä½“ç±»å‹å®šä¹‰è‡ªç„¶è¯­è¨€æ¨¡æ¿
- **å…³ç³»æ¨¡æ¿**: é’ˆå¯¹æ¯ç§å…³ç³»ç±»å‹å®šä¹‰è¿æ¥è¯­ä¹‰
- **å ä½ç¬¦å¡«å……**: è‡ªåŠ¨å¡«å……å®ä½“å±æ€§åˆ°æ¨¡æ¿
- **NA å¤„ç†**: æ˜¾ç¤ºç¼ºå¤±åŸå› è€Œé"N/A"

**ä¼˜åŠ¿**:
- æé«˜å¯è§£é‡Šæ€§
- ä¾¿äº LLM ç†è§£
- æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢

#### 7. Chunk ä½œä¸ºåŸå§‹æ•°æ®å¿«ç…§

- **è®¾è®¡**: æ¯ä¸ªå®ä½“çš„ chunk_text åŒ…å«åŸå§‹ counter æ•°æ®
- **æ ¼å¼**: ä¿ç•™åŸå§‹ Darshan log æ ¼å¼
- **ç”¨é€”**:
  - LLM å¯ä»¥è®¿é—®åŸå§‹æ•°æ®
  - æ”¯æŒç²¾ç¡®æ•°å€¼æŸ¥è¯¢
  - éªŒè¯ signal è®¡ç®—

#### 8. æœ¬åœ° Embedding

- **è®¾è®¡**: ä½¿ç”¨æœ¬åœ° Transformer æ¨¡å‹è€Œé OpenAI API
- **ä¼˜åŠ¿**:
  - æ—  API æˆæœ¬
  - æ— ç½‘ç»œä¾èµ–
  - å®Œå…¨å¯æ§
  - æ”¯æŒç¦»çº¿ç¯å¢ƒ

---

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ä»å¤´åˆ°å°¾çš„å®Œæ•´æµç¨‹

```bash
# 0. è§£å‹æ—¥å¿—
./scripts/unpack-darshan-logs.sh /path/to/darshan-logs/

# 1. è§£ææ—¥å¿—ï¼ˆä½¿ç”¨ darshan-parserï¼‰
darshan-parser /path/to/log.darshan > /path/to/log.txt

# 2. è®¡ç®— signals
python3 scripts/process_darshan_signals_v2.4.py \
    /path/to/log.txt \
    -o /path/to/log_signals_v2.4.txt

# 3. æ„å»º KG
python experiments/darshan_kg_builder_v2.1.py \
    -i /path/to/log_signals_v2.4.txt \
    -o /path/to/kg.json

# 4. ç”Ÿæˆæè¿°
python3 scripts/generate_descriptions_v3.py \
    /path/to/kg.json \
    /path/to/kg_with_desc.json

# 5. æ·»åŠ  chunks
python3 scripts/parse_darshan_chunks.py \
    --log /path/to/log.txt \
    --kg /path/to/kg_with_desc.json \
    --output /path/to/kg_with_chunks.json

# 6. ç”Ÿæˆ embeddings
python3 scripts/embed_kg_local.py \
    --kg /path/to/kg_with_chunks.json \
    --output ./embeddings \
    --model google/embeddinggemma-300m \
    --batch-size 32

# 7. åŠ è½½åˆ° LightRAG
python3 scripts/load_custom_kg_to_lightrag.py \
    --kg /path/to/kg_with_chunks.json \
    --embeddings ./embeddings \
    --embedding-model google/embeddinggemma-300m
```

### ç¤ºä¾‹ 2: æ‰¹é‡å¤„ç†å¤šä¸ªæ—¥å¿—

```bash
# æ‰¹é‡è§£æï¼ˆåœ¨ Jupyter notebook ä¸­ï¼‰
import os
import subprocess
from pathlib import Path
from tqdm import tqdm

parent_dir = '/path/to/darshan-logs/'
parsed_root = Path('~/parsed-logs/').expanduser()
parsed_root.mkdir(parents=True, exist_ok=True)

# æ”¶é›†æ‰€æœ‰ .darshan æ–‡ä»¶
darshan_logs = []
for root, dirs, files in os.walk(parent_dir):
    for file in files:
        if file.endswith('.darshan'):
            fullpath = os.path.join(root, file)
            rel = os.path.relpath(fullpath, parent_dir)
            output_dir = parsed_root / Path(rel).parent
            output_dir.mkdir(parents=True, exist_ok=True)
            out_txt = output_dir / (Path(file).stem + '.txt')
            darshan_logs.append((fullpath, out_txt))

# æ‰¹é‡è§£æ
success_count = 0
fail_count = 0

for in_log, out_txt in tqdm(darshan_logs, desc="Parsing darshan logs"):
    result = subprocess.run(
        ['darshan-parser', in_log],
        capture_output=True,
        text=True
    )

    if result.returncode == 0:
        with open(out_txt, 'w') as f:
            f.write(result.stdout)
        success_count += 1
    else:
        fail_count += 1

print(f"\nâœ… è§£æå®Œæˆ: æˆåŠŸ {success_count} ä¸ª, å¤±è´¥ {fail_count} ä¸ª")
```

### ç¤ºä¾‹ 3: åœ¨ Notebook ä¸­æŸ¥è¯¢

```python
# Cell 1: Setup
import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import openai_complete_if_cache
from lightrag.utils import EmbeddingFunc
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np

# Cell 2: API Key
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âš ï¸  è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
else:
    print("âœ… OPENAI_API_KEY å·²åŠ è½½")

# Cell 3: Local Embedding Function
class LocalEmbeddingFunction:
    def __init__(self, model_name="google/embeddinggemma-300m", device=None, batch_size=4):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.model = self.model.to(self.device).eval()
        self.embedding_dim = self.model.config.hidden_size
        self.batch_size = batch_size
        print(f"âœ“ Model loaded: {model_name} ({self.embedding_dim}D)")

    async def __call__(self, texts):
        embeddings = []
        with torch.no_grad():
            for i in range(0, len(texts), self.batch_size):
                batch = texts[i:i + self.batch_size]
                encoded = self.tokenizer(batch, padding=True, truncation=True,
                                        max_length=512, return_tensors="pt").to(self.device)
                outputs = self.model(**encoded)
                attention_mask = encoded['attention_mask']
                token_embeddings = outputs.last_hidden_state
                input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
                batch_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / \
                                  torch.clamp(input_mask_expanded.sum(1), min=1e-9)
                batch_embeddings = torch.nn.functional.normalize(batch_embeddings, p=2, dim=1)
                embeddings.append(batch_embeddings.cpu().numpy())
        return np.vstack(embeddings)

local_embed = LocalEmbeddingFunction()
embedding_func = EmbeddingFunc(
    embedding_dim=local_embed.embedding_dim,
    max_token_size=2048,
    func=lambda texts: local_embed(texts)
)

# Cell 4: LLM Function
async def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
    return await openai_complete_if_cache(
        "gpt-4o-mini",
        prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=OPENAI_API_KEY,
        **kwargs
    )

print("âœ“ LLM function configured")

# Cell 5: Load RAG
WORKING_DIR = "./lightrag_darshan_storage"

rag = LightRAG(
    working_dir=WORKING_DIR,
    embedding_func=embedding_func,
    llm_model_func=llm_model_func,
)

await rag.initialize_storages()
print("âœ“ LightRAG loaded successfully!")

# Cell 6: Query Helper
async def query(question, mode="hybrid", top_k=5):
    """æŸ¥è¯¢ Darshan KG"""
    result = await rag.aquery(
        question,
        param=QueryParam(mode=mode, top_k=top_k)
    )
    return result

print("âœ“ Query helper ready!")

# Cell 7: Example Queries
# åŸºæœ¬æŸ¥è¯¢
result = await query("What are the POSIX I/O operations?")
print(result)

# æŸ¥è¯¢æ–‡ä»¶è®¿é—®
result = await query("Which files were accessed and where?")
print(result)

# åˆ†æ I/O æ€§èƒ½
result = await rag.aquery(
    "Analyze the I/O performance",
    param=QueryParam(
        mode="hybrid",
        top_k=10,
        only_need_context=False
    )
)
print(result)
```

### ç¤ºä¾‹ 4: è‡ªå®šä¹‰æŸ¥è¯¢

```python
# åŸºäºæ—¶é—´çš„æŸ¥è¯¢
result = await query("Which records spent the most time in read operations?")

# åŸºäºæ€§èƒ½çš„æŸ¥è¯¢
result = await query("Which records achieved read bandwidth over 1000 MB/s?")

# åŸºäºè®¿é—®æ¨¡å¼çš„æŸ¥è¯¢
result = await query("Find records with high sequential access ratios on Lustre")

# è·¨å±‚çº§èšåˆæŸ¥è¯¢
result = await query("What are the average I/O characteristics for this application?")

# å…ƒæ•°æ®å¯†é›†å‹è´Ÿè½½
result = await query("Show records with high metadata intensity on NFS")

# Rank ä¸å‡è¡¡
result = await query("Which shared files have the highest rank imbalance in I/O time?")
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: `process_darshan_signals_v2.4.py` è¾“å‡ºä¸ºç©º

**å¯èƒ½åŸå› **:
- è¾“å…¥æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼ˆä¸æ˜¯ darshan-parser çš„è¾“å‡ºï¼‰
- æ–‡ä»¶ç¼–ç é—®é¢˜

**è§£å†³**:
```bash
# æ£€æŸ¥æ–‡ä»¶å¤´
head -20 input.txt

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„ header:
# darshan log version: 3.41
# compression method: BZIP2
# exe: 4068766220
# ...

# é‡æ–°è§£æ
darshan-parser input.darshan > output.txt
```

### é—®é¢˜ 2: `darshan_kg_builder_v2.1.py` æŠ¥é”™ "No records found"

**å¯èƒ½åŸå› **:
- Signal æ–‡ä»¶ä¸æ˜¯ v2.4+ æ ¼å¼
- Record section æ ¼å¼ä¸æ­£ç¡®

**è§£å†³**:
```bash
# æ£€æŸ¥ signal æ–‡ä»¶æ ¼å¼
grep "# Record:" signal_file.txt

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼:
# Record: 11610284057069735693, rank=-1, file=/home/file, mount=/home, fs=lustre
```

### é—®é¢˜ 3: `embed_kg_local.py` æŠ¥é”™ "CUDA out of memory"

**å¯èƒ½åŸå› **:
- Batch size å¤ªå¤§
- æ¨¡å‹å¤ªå¤§

**è§£å†³**:
```bash
# å‡å° batch size
python3 scripts/embed_kg_local.py \
    --kg kg.json \
    --output ./embeddings \
    --batch-size 4  # ä» 32 å‡åˆ° 4

# æˆ–ä½¿ç”¨ CPU
python3 scripts/embed_kg_local.py \
    --kg kg.json \
    --output ./embeddings \
    --device cpu
```

### é—®é¢˜ 4: `load_custom_kg_to_lightrag.py` æŠ¥é”™ "OpenAI API key not provided"

**è§£å†³**:
```bash
# æ–¹æ³• 1: ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=sk-your-key-here
python3 scripts/load_custom_kg_to_lightrag.py --kg kg.json

# æ–¹æ³• 2: å‘½ä»¤è¡Œå‚æ•°
python3 scripts/load_custom_kg_to_lightrag.py \
    --kg kg.json \
    --openai-key sk-your-key-here
```

### é—®é¢˜ 5: LightRAG æŸ¥è¯¢ç»“æœä¸å‡†ç¡®

**å¯èƒ½åŸå› **:
- Embedding æ¨¡å‹ä¸ä¸€è‡´
- Top-k å¤ªå°
- æŸ¥è¯¢æ¨¡å¼ä¸åˆé€‚

**è§£å†³**:
```python
# 1. å¢åŠ  top_k
result = await query("question", mode="hybrid", top_k=20)

# 2. å°è¯•ä¸åŒçš„æŸ¥è¯¢æ¨¡å¼
result = await query("question", mode="local")  # å±€éƒ¨æœç´¢
result = await query("question", mode="global")  # å…¨å±€æœç´¢
result = await query("question", mode="mix")  # æ··åˆæœç´¢

# 3. å¯ç”¨ rerankï¼ˆéœ€è¦é…ç½® rerank æ¨¡å‹ï¼‰
result = await rag.aquery(
    "question",
    param=QueryParam(mode="hybrid", enable_rerank=True)
)
```

---

## æ–‡ä»¶ç»“æ„

```
/users/Minqiu/DarshanRAG/experiments/
â”œâ”€â”€ config_paths.py                      # è·¯å¾„é…ç½®æ¨¡å—
â”œâ”€â”€ darshan_kg_builder_v2.1.py           # KG æ„å»ºè„šæœ¬
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ IORAG.ipynb                      # ä¸» notebook
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ unpack-darshan-logs.sh           # è§£å‹æ—¥å¿—
â”‚   â”œâ”€â”€ process_darshan_signals_v2.4.py  # ä¿¡å·æå–
â”‚   â”œâ”€â”€ generate_descriptions_v3.py      # ç”Ÿæˆæè¿°
â”‚   â”œâ”€â”€ parse_darshan_chunks.py          # è§£æ chunks
â”‚   â”œâ”€â”€ embed_kg_local.py                # æœ¬åœ°åµŒå…¥
â”‚   â”œâ”€â”€ embed_kg_cpu_optimized.sh        # CPU ä¼˜åŒ–åµŒå…¥
â”‚   â””â”€â”€ load_custom_kg_to_lightrag.py    # åŠ è½½ KG
â”œâ”€â”€ results/                             # ç»“æœè¾“å‡º
â”œâ”€â”€ storage/                             # RAG å­˜å‚¨
â”œâ”€â”€ ground_truth/                        # çœŸå€¼æ•°æ®
â””â”€â”€ IORAG_README.md                      # æœ¬æ–‡æ¡£
```

---

## å‚è€ƒèµ„æ–™

- [LightRAG GitHub](https://github.com/HKUDS/LightRAG)
- [Darshan Documentation](https://www.mcs.anl.gov/research/projects/darshan/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [google/embeddinggemma-300m](https://huggingface.co/google/embeddinggemma-300m)
- [Sentence Transformers](https://www.sbert.net/)

---

## ç‰ˆæœ¬å†å²

- **v1.0** (2026-02-10): åˆå§‹ç‰ˆæœ¬
  - å®Œæ•´ workflow æ–‡æ¡£
  - æ‰€æœ‰è„šæœ¬è¯¦è§£
  - Signal è®¡ç®—è§„æ ¼
  - è®¾è®¡æ€è·¯è¯´æ˜

---

**Author**: Claude
**Date**: 2026-02-10
**Version**: 1.0
